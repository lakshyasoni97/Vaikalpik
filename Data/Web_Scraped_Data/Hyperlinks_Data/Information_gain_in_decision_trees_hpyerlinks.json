{"Wikipedia:Verifiability": "/wiki/Wikipedia:Verifiability", "Help:Referencing for beginners": "/wiki/Help:Referencing_for_beginners", "Help:Maintenance template removal": "/wiki/Help:Maintenance_template_removal", "Information theory": "/wiki/Information_theory", "Machine learning": "/wiki/Machine_learning", "Kullback\u2013Leibler divergence": "/wiki/Kullback%E2%80%93Leibler_divergence", "Information content": "/wiki/Information_content", "Random variable": "/wiki/Random_variable", "Signal": "/wiki/Signal", "Mutual information": "/wiki/Mutual_information", "Conditional expectation": "/wiki/Conditional_expectation", "Probability distribution": "/wiki/Probability_distribution", "Conditional probability distribution": "/wiki/Conditional_probability_distribution", "Conditional probability": "/wiki/Conditional_probability", "Prior distribution": "/wiki/Prior_distribution", "Posterior distribution": "/wiki/Posterior_distribution", "Expected value": "/wiki/Expected_value", "Information entropy": "/wiki/Information_entropy", "Decision tree": "/wiki/Decision_tree", "Decision tree learning": "/wiki/Decision_tree_learning", "Wikipedia:Please clarify": "/wiki/Wikipedia:Please_clarify", "Edit section: General definition": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=1", "Expectation value": "/wiki/Expectation_value", "Conditional entropy": "/wiki/Conditional_entropy", "Feature (machine learning)": "/wiki/Feature_(machine_learning)", "Edit section: Formal definition": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=2", "Training set": "/wiki/Training_set", "Feature vector": "/wiki/Feature_vector", "Shannon entropy": "/wiki/Shannon_entropy", "Set (mathematics)": "/wiki/Set_(mathematics)", "Statistical classification": "/wiki/Statistical_classification", "Partition of a set": "/wiki/Partition_of_a_set", "Disjoint sets": "/wiki/Disjoint_sets", "Subset": "/wiki/Subset", "Categorical distribution": "/wiki/Categorical_distribution", "Edit section: Another Take on Information Gain, with Example": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=3", "Analogy": "/wiki/Analogy", "Enlarge": "/wiki/File:Entropy-illustration.png", "Mutation": "/wiki/Mutation", "Training, validation, and test sets": "/wiki/Training,_validation,_and_test_sets", "Overfitting": "/wiki/Overfitting", "Hereditary set": "/wiki/Hereditary_set", "Edit section: Advantages": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=4", "Optimal": "/wiki/Optimal", "C4.5 algorithm": "/wiki/C4.5_algorithm", "Continuous or discrete variable": "/wiki/Continuous_or_discrete_variable", "Edit section: Drawbacks and Solutions": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=5", "Relevance": "/wiki/Relevance", "Ross Quinlan": "/wiki/Ross_Quinlan", "Information gain ratio": "/wiki/Information_gain_ratio", "Edit section: See also": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=6", "Information gain": "/wiki/Information_gain", "Entropy (information theory)": "/wiki/Entropy_(information_theory)", "ID3 algorithm": "/wiki/ID3_algorithm", "Surprisal analysis": "/wiki/Surprisal_analysis", "Edit section: References": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=7", "Wiley (publisher)": "/wiki/Wiley_(publisher)", "ISBN (identifier)": "/wiki/ISBN_(identifier)", "Special:BookSources/9780470908747": "/wiki/Special:BookSources/9780470908747", "Doi (identifier)": "/wiki/Doi_(identifier)", "Machine Learning (journal)": "/wiki/Machine_Learning_(journal)", "Stack Exchange": "/wiki/Stack_Exchange", "Edit section: Further reading": "/w/index.php?title=Information_gain_(decision_tree)&action=edit&section=8", "ArXiv (identifier)": "/wiki/ArXiv_(identifier)", "Tom M. Mitchell": "/wiki/Tom_M._Mitchell", "Special:BookSources/978-0070428072": "/wiki/Special:BookSources/978-0070428072"}