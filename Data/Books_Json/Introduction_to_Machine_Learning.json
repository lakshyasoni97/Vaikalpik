{"Name": "Introduction_to_Machine_Learning.pdf", "Pages": {"0": "Contents\nPreface xvii\nNotations xxi\n1Introduction 1\n1.1 What Is Machine Learning? 1\n1.2 Examples of Machine Learning Applications 4\n1.2.1 Learning Associations 4\n1.2.2 Classi\ufb01cation 5\n1.2.3 Regression 9\n1.2.4 Unsupervised Learning 111.2.5 Reinforcement Learning 13\n1.3 Notes 14\n1.4 Relevant Resources 17\n1.5 Exercises 18\n1.6 References 20\n2Supervised Learning 21\n2.1 Learning a Class from Examples 21\n2.2 Vapnik-Chervonenkis Dimension 27\n2.3 Probably Approximately Correct Learning 292.4 Noise 30\n2.5 Learning Multiple Classes 32\n2.6 Regression 34\n2.7 Model Selection and Generalization 37\n2.8 Dimensions of a Supervised Machine Learning Algorithm 41\n2.9 Notes 42\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "1": "viii Contents\n2.10 Exercises 43\n2.11 References 47\n3Bayesian Decision Theory 49\n3.1 Introduction 49\n3.2 Classi\ufb01cation 513.3 Losses and Risks 533.4 Discriminant Functions 55\n3.5 Association Rules 56\n3.6 Notes 59\n3.7 Exercises 60\n3.8 References 64\n4Parametric Methods 65\n4.1 Introduction 65\n4.2 Maximum Likelihood Estimation 66\n4.2.1 Bernoulli Density 67\n4.2.2 Multinomial Density 684.2.3 Gaussian (Normal) Density 68\n4.3 Evaluating an Estimator: Bias and Variance 694.4 The Bayes\u2019 Estimator 70\n4.5 Parametric Classi\ufb01cation 73\n4.6 Regression 774.7 Tuning Model Complexity: Bias/Variance Dilemma 80\n4.8 Model Selection Procedures 83\n4.9 Notes 874.10 Exercises 884.11 References 90\n5Multivariate Methods 93\n5.1 Multivariate Data 93\n5.2 Parameter Estimation 945.3 Estimation of Missing Values 955.4 Multivariate Normal Distribution 965.5 Multivariate Classi\ufb01cation 100\n5.6 Tuning Complexity 1065.7 Discrete Features 108\n5.8 Multivariate Regression 109\n5.9 Notes 111\n5.10 Exercises 112\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "2": "Contents ix\n5.11 References 113\n6Dimensionality Reduction 115\n6.1 Introduction 115\n6.2 Subset Selection 1166.3 Principal Component Analysis 1206.4 Feature Embedding 1276.5 Factor Analysis 1306.6 Singular Value Decomposition and Matrix Factorization 1356.7 Multidimensional Scaling 136\n6.8 Linear Discriminant Analysis 140\n6.9 Canonical Correlation Analysis 1456.10 Isomap 1486.11 Locally Linear Embedding 150\n6.12 Laplacian Eigenmaps 153\n6.13 Notes 1556.14 Exercises 1576.15 References 158\n7Clustering 161\n7.1 Introduction 161\n7.2 Mixture Densities 162\n7.3k-Means Clustering 163\n7.4 Expectation-Maximization Algorithm 167\n7.5 Mixtures of Latent Variable Models 172\n7.6 Supervised Learning after Clustering 173\n7.7 Spectral Clustering 175\n7.8 Hierarchical Clustering 1767.9 Choosing the Number of Clusters 1787.10 Notes 1797.11 Exercises 180\n7.12 References 182\n8Nonparametric Methods 185\n8.1 Introduction 185\n8.2 Nonparametric Density Estimation 186\n8.2.1 Histogram Estimator 1878.2.2 Kernel Estimator 188\n8.2.3k-Nearest Neighbor Estimator 190\n8.3 Generalization to Multivariate Data 192\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "3": "x Contents\n8.4 Nonparametric Classi\ufb01cation 193\n8.5 Condensed Nearest Neighbor 194\n8.6 Distance-Based Classi\ufb01cation 196\n8.7 Outlier Detection 1998.8 Nonparametric Regression: Smoothing Models 201\n8.8.1 Running Mean Smoother 201\n8.8.2 Kernel Smoother 203\n8.8.3 Running Line Smoother 204\n8.9 How to Choose the Smoothing Parameter 2048.10 Notes 2058.11 Exercises 208\n8.12 References 210\n9Decision Trees 213\n9.1 Introduction 213\n9.2 Univariate Trees 215\n9.2.1 Classi\ufb01cation Trees 2169.2.2 Regression Trees 220\n9.3 Pruning 2229.4 Rule Extraction from Trees 2259.5 Learning Rules from Data 2269.6 Multivariate Trees 2309.7 Notes 232\n9.8 Exercises 235\n9.9 References 237\n10Linear Discrimination 239\n10.1 Introduction 239\n10.2 Generalizing the Linear Model 24110.3 Geometry of the Linear Discriminant 242\n10.3.1 Two Classes 242\n10.3.2 Multiple Classes 244\n10.4 Pairwise Separation 246\n10.5 Parametric Discrimination Revisited 24710.6 Gradient Descent 24810.7 Logistic Discrimination 250\n10.7.1 Two Classes 25010.7.2 Multiple Classes 254\n10.8 Discrimination by Regression 257\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "4": "Contents xi\n10.9 Learning to Rank 260\n10.10 Notes 263\n10.11 Exercises 263\n10.12 References 266\n11Multilayer Perceptrons 267\n11.1 Introduction 267\n11.1.1 Understanding the Brain 268\n11.1.2 Neural Networks as a Paradigm for Parallel\nProcessing 269\n11.2 The Perceptron 27111.3 Training a Perceptron 27411.4 Learning Boolean Functions 277\n11.5 Multilayer Perceptrons 279\n11.6 MLP as a Universal Approximator 28111.7 Backpropagation Algorithm 283\n11.7.1 Nonlinear Regression 28411.7.2 Two-Class Discrimination 286\n11.7.3 Multiclass Discrimination 288\n11.7.4 Multiple Hidden Layers 290\n11.8 Training Procedures 290\n11.8.1 Improving Convergence 29011.8.2 Overtraining 291\n11.8.3 Structuring the Network 292\n11.8.4 Hints 295\n11.9 Tuning the Network Size 29711.10 Bayesian View of Learning 300\n11.11 Dimensionality Reduction 301\n11.12 Learning Time 304\n11.12.1 Time Delay Neural Networks 30411.12.2 Recurrent Networks 305\n11.13 Deep Learning 306\n11.14 Notes 309\n11.15 Exercises 31111.16 References 313\n12Local Models 317\n12.1 Introduction 317\n12.2 Competitive Learning 318\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "5": "xii Contents\n12.2.1 Online k-Means 318\n12.2.2 Adaptive Resonance Theory 32312.2.3 Self-Organizing Maps 324\n12.3 Radial Basis Functions 32612.4 Incorporating Rule-Based Knowledge 332\n12.5 Normalized Basis Functions 333\n12.6 Competitive Basis Functions 33512.7 Learning Vector Quantization 33812.8 The Mixture of Experts 338\n12.8.1 Cooperative Experts 34112.8.2 Competitive Experts 342\n12.9 Hierarchical Mixture of Experts 34212.10 Notes 343\n12.11 Exercises 344\n12.12 References 347\n13Kernel Machines 349\n13.1 Introduction 349\n13.2 Optimal Separating Hyperplane 35113.3 The Nonseparable Case: Soft Margin Hyperplane 35513.4\u03bd-SVM 358\n13.5 Kernel Trick 359\n13.6 Vectorial Kernels 361\n13.7 De\ufb01ning Kernels 364\n13.8 Multiple Kernel Learning 36513.9 Multiclass Kernel Machines 36713.10 Kernel Machines for Regression 36813.11 Kernel Machines for Ranking 37313.12 One-Class Kernel Machines 37413.13 Large Margin Nearest Neighbor Classi\ufb01er 37713.14 Kernel Dimensionality Reduction 379\n13.15 Notes 380\n13.16 Exercises 382\n13.17 References 383\n14Graphical Models 387\n14.1 Introduction 387\n14.2 Canonical Cases for Conditional Independence 38914.3 Generative Models 396\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "6": "Contents xiii\n14.4 d-Separation 399\n14.5 Belief Propagation 399\n14.5.1 Chains 40014.5.2 Trees 40214.5.3 Polytrees 404\n14.5.4 Junction Trees 406\n14.6 Undirected Graphs: Markov Random Fields 407\n14.7 Learning the Structure of a Graphical Model 410\n14.8 In\ufb02uence Diagrams 41114.9 Notes 41214.10 Exercises 41314.11 References 415\n15Hidden Markov Models 417\n15.1 Introduction 417\n15.2 Discrete Markov Processes 41815.3 Hidden Markov Models 421\n15.4 Three Basic Problems of HMMs 423\n15.5 Evaluation Problem 423\n15.6 Finding the State Sequence 427\n15.7 Learning Model Parameters 42915.8 Continuous Observations 43215.9 The HMM as a Graphical Model 433\n15.10 Model Selection in HMMs 436\n15.11 Notes 43815.12 Exercises 44015.13 References 443\n16Bayesian Estimation 445\n16.1 Introduction 445\n16.2 Bayesian Estimation of the Parameters of a Discrete\nDistribution 449\n16.2.1K>2 States: Dirichlet Distribution 449\n16.2.2K=2 States: Beta Distribution 450\n16.3 Bayesian Estimation of the Parameters of a Gaussian\nDistribution 451\n16.3.1 Univariate Case: Unknown Mean, Known\nVariance 451\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "7": "xiv Contents\n16.3.2 Univariate Case: Unknown Mean, Unknown\nVariance 453\n16.3.3 Multivariate Case: Unknown Mean, Unknown\nCovariance 455\n16.4 Bayesian Estimation of the Parameters of a Function 456\n16.4.1 Regression 456\n16.4.2 Regression with Prior on Noise Precision 46016.4.3 The Use of Basis/Kernel Functions 461\n16.4.4 Bayesian Classi\ufb01cation 463\n16.5 Choosing a Prior 466\n16.6 Bayesian Model Comparison 46716.7 Bayesian Estimation of a Mixture Model 470\n16.8 Nonparametric Bayesian Modeling 473\n16.9 Gaussian Processes 47416.10 Dirichlet Processes and Chinese Restaurants 478\n16.11 Latent Dirichlet Allocation 480\n16.12 Beta Processes and Indian Bu\ufb00ets 48216.13 Notes 483\n16.14 Exercises 484\n16.15 References 485\n17Combining Multiple Learners 487\n17.1 Rationale 487\n17.2 Generating Diverse Learners 488\n17.3 Model Combination Schemes 491\n17.4 Voting 492\n17.5 Error-Correcting Output Codes 496\n17.6 Bagging 498\n17.7 Boosting 499\n17.8 The Mixture of Experts Revisited 50217.9 Stacked Generalization 504\n17.10 Fine-Tuning an Ensemble 505\n17.10.1 Choosing a Subset of the Ensemble 50617.10.2 Constructing Metalearners 506\n17.11 Cascading 507\n17.12 Notes 509\n17.13 Exercises 51117.14 References 513\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "8": "Contents xv\n18Reinforcement Learning 517\n18.1 Introduction 517\n18.2 Single State Case: K-Armed Bandit 519\n18.3 Elements of Reinforcement Learning 520\n18.4 Model-Based Learning 523\n18.4.1 Value Iteration 52318.4.2 Policy Iteration 524\n18.5 Temporal Di\ufb00erence Learning 525\n18.5.1 Exploration Strategies 52518.5.2 Deterministic Rewards and Actions 52618.5.3 Nondeterministic Rewards and Actions 527\n18.5.4 Eligibility Traces 530\n18.6 Generalization 53118.7 Partially Observable States 534\n18.7.1 The Setting 53418.7.2 Example: The Tiger Problem 536\n18.8 Notes 54118.9 Exercises 542\n18.10 References 544\n19Design and Analysis of Machine Learning Experiments 547\n19.1 Introduction 547\n19.2 Factors, Response, and Strategy of Experimentation 550\n19.3 Response Surface Design 553\n19.4 Randomization, Replication, and Blocking 55419.5 Guidelines for Machine Learning Experiments 55519.6 Cross-Validation and Resampling Methods 558\n19.6.1K-Fold Cross-Validation 559\n19.6.2 5\u00d72 Cross-Validation 560\n19.6.3 Bootstrapping 561\n19.7 Measuring Classi\ufb01er Performance 561\n19.8 Interval Estimation 564\n19.9 Hypothesis Testing 56819.10 Assessing a Classi\ufb01cation Algorithm\u2019s Performance 570\n19.10.1 Binomial Test 57119.10.2 Approximate Normal Test 57219.10.3tTest 572\n19.11 Comparing Two Classi\ufb01cation Algorithms 573\n19.11.1 McNemar\u2019s Test 573\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n", "9": "xvi Contents\n19.11.2K-Fold Cross-Validated Paired tTest 573\n19.11.3 5\u00d72 cv PairedtTest 574\n19.11.4 5\u00d72 cv PairedFTest 575\n19.12 Comparing Multiple Algorithms: Analysis of Variance 57619.13 Comparison over Multiple Datasets 580\n19.13.1 Comparing Two Algorithms 58119.13.2 Multiple Algorithms 583\n19.14 Multivariate Tests 584\n19.14.1 Comparing Two Algorithms 58519.14.2 Comparing Multiple Algorithms 586\n19.15 Notes 587\n19.16 Exercises 58819.17 References 590\nAProbability 593\nA.1 Elements of Probability 593\nA.1.1 Axioms of Probability 594A.1.2 Conditional Probability 594\nA.2 Random Variables 595\nA.2.1 Probability Distribution and Density Functions 595A.2.2 Joint Distribution and Density Functions 596\nA.2.3 Conditional Distributions 596\nA.2.4 Bayes\u2019 Rule 597\nA.2.5 Expectation 597\nA.2.6 Variance 598A.2.7 Weak Law of Large Numbers 599\nA.3 Special Random Variables 599\nA.3.1 Bernoulli Distribution 599\nA.3.2 Binomial Distribution 600\nA.3.3 Multinomial Distribution 600A.3.4 Uniform Distribution 600A.3.5 Normal (Gaussian) Distribution 601A.3.6 Chi-Square Distribution 602\nA.3.7tDistribution 603\nA.3.8FDistribution 603\nA.4 References 603\nIndex 605\nAlpaydin, Ethem. Introduction to Machine Learning, MIT Press, 2014. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/jiouniv/detail.action?docID=3339851.\nCreated from jiouniv on 2023-03-30 13:02:46.\nCopyright \u00a9 2014. MIT Press. All rights reserved. \n"}}